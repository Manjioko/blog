# 热点key重建
在使用redis做缓存的时候，会出现这样的情况：  
1. 查询的key是一个热点key，即key的访问量非常大，如时下的热点新闻
2. 缓存重新构建的时间比较长，或者比较损耗性能，如需要做一些计算之类的

如果我们采用通常的策略，即设置一个缓存过期时间，由于是热点数据，当缓存过期的时候，就会出现大量请求来重新构建缓存，如果缓存的构建需要复杂的计算，很有可能会拖垮服务端。

如何避免这种情况的发生？

## 不设置缓存过期时间
首先如果key不过期，那么就不会出现热点key过期的问题。但是这里的不过期，只是在redis层面不设置key的过期时间。

然后我们把过期时间设置在value里面，如果当查询该热点key后发现value中的过期时间已经小于等于当前时间，那么通过开辟一个独立的线程去进行缓存构建，同时返回旧的value值。  
为了避免多个线程在构建缓存，需要用到分布式锁。

那么就会出现
```
  （T1）
获取缓存  ----无等待-------> 输出
获取缓存  ----无等待-------> 输出
   (T2)
获取缓存  ----发现value中的过期时间过期，进行异步更新-------> 输出旧值 （T4完成缓存构建）
  （T3）
获取缓存  ----无等待-------> 输出旧值
获取缓存  ----无等待-------> 输出旧值
  (T4)
获取缓存  ----无等待-------> 输出新值
获取缓存  ----无等待-------> 输出新值
```

如果使用node，由于是单线程异步的可以很简单做到这一点
```javascript
// 重新构建缓存，分布式锁还可以用redlock库来做
async function buildCache(key, value) {
  const keyMutex = `mutex:${key}`
  if (await redis.setnx(keyMutex, '1')) {
    // 避免锁无法释放
    await redis.expire(keyMutex, 3 * 60)
    // 获取最新的数据
    const newData = db.get(key)
    const newValue = JSON.stringify({
      data: newData,
      timeout: Date.now() + 10 * 60 * 1000
    })
    await redis.set(key, newValue)
    await redis.del(keyMutex)
  }
}

async function get(key) {
  const value = await redis.get(key)
  const {data, timeout} = JSON.parse(value)
  
  if (timeout <= Date.now()) {
    // 已经过期
    buildCache(key)
  }

  // 返回旧数据
  return data
}
```
